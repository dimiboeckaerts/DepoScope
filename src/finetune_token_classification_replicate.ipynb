{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc0aab7",
   "metadata": {},
   "source": [
    "# Finetuning the ESM2 token classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ea270f",
   "metadata": {},
   "source": [
    "### 0. Libraries & path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169dd8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411cb62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# absolute path to project\n",
    "absolute_path = '/Users/dimi/Documents/GitHub/PhageDEPOdetection/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d118b",
   "metadata": {},
   "source": [
    "### 1. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adfd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(df , label = 1) :\n",
    "    labels_df = []\n",
    "    for _,row in df.iterrows():\n",
    "        info = row[\"Boundaries\"]\n",
    "        seq_length = len(row[\"Full_seq\"])\n",
    "        if info == \"Negative\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        elif info == \"full_protein\" or info == \"full\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        elif info.count(\":\") > 0 : \n",
    "            start = int(info.split(\":\")[0])\n",
    "            end = int(info.split(\":\")[1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "        else :\n",
    "            start = int(info.split(\"_\")[-2])\n",
    "            end = int(info.split(\"_\")[-1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "    return labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77a2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(inputs):\n",
    "    \"\"\"\n",
    "    ESM finetuning needs input_ids, attention_mask, labels, position_ids.\n",
    "    If the dataset does not contain these columns, we need to add them w this function.\n",
    "    \"\"\"\n",
    "    return tokenizer(inputs['tokens'], add_special_tokens=False, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ed8253e",
   "metadata": {},
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    labels = list(labels)\n",
    "    predictions = list(np.argmax(predictions, axis=2))\n",
    "    # Remove ignored index (special tokens)\n",
    "    #true_predictions = [\n",
    "    #    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    #    for prediction, label in zip(predictions, labels)]\n",
    "    #true_labels = [\n",
    "    #    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    #    for prediction, label in zip(predictions, labels)]\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions),\n",
    "            \"precision\": precision_score(labels, predictions),\n",
    "            \"recall\": recall_score(labels, predictions),\n",
    "            \"f1\": f1_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22967d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## second attempt. If this doensn't work, problem with 0-preds that prevent recall etc..?\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    results = seqeval.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \n",
    "            \"f1\": results[\"overall_f1\"], \"accuracy\": results[\"overall_accuracy\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff121cec",
   "metadata": {},
   "source": [
    "### 2. Code to finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3abb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_depo = pd.read_csv(absolute_path+'data/Phagedepo.Dataset.2007.tsv' , sep = '\\t' , header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7885d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign and get the labels\n",
    "df_beta_helix = df_depo[df_depo[\"Fold\"] == \"right-handed beta-helix\"]\n",
    "df_beta_prope = df_depo[df_depo[\"Fold\"] == \"6-bladed beta-propeller\"]\n",
    "df_beta_triple =  df_depo[df_depo[\"Fold\"] == \"triple-helix\"]\n",
    "df_negative = df_depo[df_depo[\"Fold\"] == \"Negative\"]\n",
    "\n",
    "labels_beta_helix = get_labels(df_beta_helix , label = 1)\n",
    "seq_beta_helix = df_beta_helix[\"Full_seq\"].to_list()\n",
    "labels_beta_propeller = get_labels(df_beta_prope , label = 2)\n",
    "seq_beta_propeller = df_beta_prope[\"Full_seq\"].to_list()\n",
    "labels_triple_helix = get_labels(df_beta_triple , label = 1)\n",
    "seq_triple_helix = df_beta_triple[\"Full_seq\"].to_list()\n",
    "labels_negative = get_labels(df_negative , label = 0)\n",
    "seq_negative = df_negative[\"Full_seq\"].to_list()\n",
    "\n",
    "# final input data\n",
    "sequences = seq_beta_helix + seq_beta_propeller + seq_triple_helix + seq_negative\n",
    "labels = labels_beta_helix + labels_beta_propeller + labels_triple_helix + labels_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e004a138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accomodate for max length of ESM2\n",
    "max_length = 1024\n",
    "sequences = [seq[:max_length] for seq in sequences]\n",
    "labels = [lab[:max_length] for lab in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97632f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.2, random_state = 243)\n",
    "train_esm2 , train_CNV , esm2_labels , CNV_labels = train_test_split(train_sequences, train_labels, test_size=0.25, random_state = 243)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7227bb5b",
   "metadata": {},
   "source": [
    "# THIS DOES NOT WORK...\n",
    "# make a dataset out of it -> this prevents the labels from being longer than the tokens later\n",
    "#max_length = 1024 # max length for ESM2\n",
    "#finetune_data = {'version': '0.1.0', 'train': [], 'test': []}\n",
    "#for i, sequence in enumerate(train_esm2):\n",
    "#    tokens = list(sequence)[:max_length]\n",
    "#    labels = esm2_labels[i][:max_length]\n",
    "#    this_data = {'id': i, 'tokens': tokens, 'labels': labels}\n",
    "#    finetune_data['train'].append(this_data)\n",
    "#for i, sequence in enumerate(test_sequences):\n",
    "#    tokens = list(sequence)[:max_length]\n",
    "#    labels = test_labels[i][:max_length]\n",
    "#    this_data = {'id': i, 'tokens': tokens, 'labels': labels}\n",
    "#    finetune_data['test'].append(this_data)\n",
    "# create datasets\n",
    "#finetune_train = Dataset.from_dict(finetune_train)\n",
    "#finetune_test = Dataset.from_dict(finetune_test)\n",
    "# create datasetdict (merged)\n",
    "#finetune_data = DatasetDict()\n",
    "#finetune_data['train'] = finetune_train\n",
    "#finetune_data['test'] = finetune_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc5ebf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing EsmForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# initialize the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"facebook/esm2_t6_8M_UR50D\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9017f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the data and make a dataset from it\n",
    "train_tokenized = tokenizer(train_esm2, add_special_tokens=False, padding='max_length', truncation=True, max_length=1024)\n",
    "test_tokenized = tokenizer(test_sequences, add_special_tokens=False, padding='max_length', truncation=True, max_length=1024)\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "train_dataset = train_dataset.add_column(\"labels\", esm2_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e54d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1373\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de0493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=absolute_path+'data/finetune',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, #16\n",
    "    per_device_eval_batch_size=8, #16\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.001,\n",
    "    #load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1691e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1373\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 688\n",
      "  Number of trainable parameters = 7738364\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/688 14:23 < 14:23, 0.40 it/s, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='58' max='58' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [58/58 02:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 458\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')},\nInput predictions: [0 0 0 ... 0 0 0],\nInput references: [0 0 0 ... 0 0 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p1/fvz7cyr12yl0lf647b14byy80000gn/T/ipykernel_2526/1718402172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         )\n\u001b[0;32m-> 1543\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2129\u001b[0m                     )\n\u001b[1;32m   2130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2131\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2827\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   2828\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3114\u001b[0m                 )\n\u001b[1;32m   3115\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p1/fvz7cyr12yl0lf647b14byy80000gn/T/ipykernel_2526/3668718647.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"], \n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/evaluate/module.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/lib/python3.9/site-packages/evaluate/module.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m                     \u001b[0;34mf\"Input references: {summarize_if_long_list(references)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 )\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions and/or references don't match the expected format.\nExpected format: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')},\nInput predictions: [0 0 0 ... 0 0 0],\nInput references: [0 0 0 ... 0 0 0]"
     ]
    }
   ],
   "source": [
    "# set the trainer and train\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model & tokenizer\n",
    "trainer.save_model('data/finetune')\n",
    "tokenizer.save_pretrained('data/finetune')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
