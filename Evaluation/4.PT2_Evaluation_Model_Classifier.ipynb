{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "from torch import nn \n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score , matthews_corrcoef, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "#path_work = \"/home/conchae/PhageDepo_pdb\"\n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "\n",
    "df_depo = pd.read_csv(f\"{path_work}/Phagedepo.Dataset.2007.tsv\" , sep = \"\\t\" , header = 0)\n",
    "\n",
    "df_beta_helix = df_depo[df_depo[\"Fold\"] == \"right-handed beta-helix\"]\n",
    "df_beta_prope = df_depo[df_depo[\"Fold\"] == \"6-bladed beta-propeller\"]\n",
    "df_beta_triple =  df_depo[df_depo[\"Fold\"] == \"triple-helix\"]\n",
    "df_negative = df_depo[df_depo[\"Fold\"] == \"Negative\"]\n",
    "\n",
    "# The phage proteins associated with PL16\n",
    "pl16_interpro = SeqIO.parse(f\"{path_work}/PL_16.phage_proteins.fasta\" , \"fasta\")\n",
    "seq_pl16_interpro = [str(record.seq) for record in pl16_interpro]\n",
    "labels_pl16 = [1]*len(seq_pl16_interpro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq_ID</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Boundaries</th>\n",
       "      <th>Full_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>PL16__112</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>110:310</td>\n",
       "      <td>MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>PL16__71</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>0:210</td>\n",
       "      <td>MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>PL16__90</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>138:336</td>\n",
       "      <td>MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>PL16__94</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>137:336</td>\n",
       "      <td>MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>PL16__156</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>140:340</td>\n",
       "      <td>MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>A0A7Z6TP65</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>41:226</td>\n",
       "      <td>MTVGRRVFLGAFTAGAVTVATGSEAAADGEYTLYTSPAQFYGSSTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>A0A1D8G892</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>42:252</td>\n",
       "      <td>MGVTRRLFLGGFTAGAVTVAAGGDAVAAEAGGDAVAAEAAGETTVF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>A0A5C4XFE5</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>61:292</td>\n",
       "      <td>MKGDTGTAGAKGDTGDTGPAGPGVAAGGTTNQFLIKSSSTNYATTW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>A0A1G9HV85</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>30:302</td>\n",
       "      <td>MTSRRLFLGAFTAGAVTVAAGASEAAAAEAEGVVEGDTTFTGAVKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>A0A6B3B193</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>183:388</td>\n",
       "      <td>MPEGIPTVTVRGRFLALDGKPRRGQVEFRVPDTVTFDAHDVILSGP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Seq_ID          Fold    Prob Boundaries  \\\n",
       "1409   PL16__112  triple-helix  manual    110:310   \n",
       "1410    PL16__71  triple-helix  manual      0:210   \n",
       "1411    PL16__90  triple-helix  manual    138:336   \n",
       "1412    PL16__94  triple-helix  manual    137:336   \n",
       "1413   PL16__156  triple-helix  manual    140:340   \n",
       "...          ...           ...     ...        ...   \n",
       "1586  A0A7Z6TP65  triple-helix  manual     41:226   \n",
       "1587  A0A1D8G892  triple-helix  manual     42:252   \n",
       "1588  A0A5C4XFE5  triple-helix  manual     61:292   \n",
       "1589  A0A1G9HV85  triple-helix  manual     30:302   \n",
       "1590  A0A6B3B193  triple-helix  manual    183:388   \n",
       "\n",
       "                                               Full_seq  \n",
       "1409  MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "1410  MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "1411  MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "1412  MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "1413  MSENIPLRVQFKRMTASEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "...                                                 ...  \n",
       "1586  MTVGRRVFLGAFTAGAVTVATGSEAAADGEYTLYTSPAQFYGSSTT...  \n",
       "1587  MGVTRRLFLGGFTAGAVTVAAGGDAVAAEAGGDAVAAEAAGETTVF...  \n",
       "1588  MKGDTGTAGAKGDTGDTGPAGPGVAAGGTTNQFLIKSSSTNYATTW...  \n",
       "1589  MTSRRLFLGAFTAGAVTVAAGASEAAAAEAEGVVEGDTTFTGAVKA...  \n",
       "1590  MPEGIPTVTVRGRFLALDGKPRRGQVEFRVPDTVTFDAHDVILSGP...  \n",
       "\n",
       "[182 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta_triple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T12\n",
    "#esm2_model_path = f\"{path_work}/esm2_t12_35M_UR50D-finetuned-depolymerase.labels_3/checkpoint-6015\"\n",
    "#DpoDetection_path = f\"{path_work}/DepoDetection.T12.3Labels.1908.model\"\n",
    "\n",
    "esm2_model_path = f\"{path_work}/esm2_t12_35M_UR50D-finetuned-depolymerase.labels_4/checkpoint-6015\"\n",
    "DpoDetection_path = f\"{path_work}/DepoDetection.T12.4Labels.1908.model\"\n",
    "\n",
    "# T6\n",
    "#esm2_model_path = f\"{path_work}/esm2_t6_8M_UR50D-finetuned-depolymerase.labels_4/checkpoint-6015\"\n",
    "#DpoDetection_path = f\"{path_work}/DepoDetection.T6.4Labels.1908.model\"\n",
    "\n",
    "#esm2_model_path = f\"{path_work}/esm2_t6_8M_UR50D-finetuned-depolymerase.labels_3/checkpoint-6015\"\n",
    "#DpoDetection_path = f\"{path_work}/DepoDetection.T6.3Labels.1908.model\"\n",
    "\n",
    "# T30\n",
    "#esm2_model_path = f\"{path_work}/script_files/esm2_t12_35M_UR50D-finetuned-depolymerase.1608.3_labels.final/checkpoint-6015\"\n",
    "#DpoDetection_path = f\"{path_work}/DepoDetection.esm2_t30_150M_UR50D.1608.final.model\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(esm2_model_path)\n",
    "esm2_finetuned = AutoModelForTokenClassification.from_pretrained(esm2_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dpo_classifier(\n",
       "  (pretrained_model): EsmForTokenClassification(\n",
       "    (esm): EsmModel(\n",
       "      (embeddings): EsmEmbeddings(\n",
       "        (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
       "      )\n",
       "      (encoder): EsmEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x EsmLayer(\n",
       "            (attention): EsmAttention(\n",
       "              (self): EsmSelfAttention(\n",
       "                (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (rotary_embeddings): RotaryEmbedding()\n",
       "              )\n",
       "              (output): EsmSelfOutput(\n",
       "                (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (intermediate): EsmIntermediate(\n",
       "              (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            )\n",
       "            (output): EsmOutput(\n",
       "              (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (contact_head): EsmContactPredictionHead(\n",
       "        (regression): Linear(in_features=240, out_features=1, bias=True)\n",
       "        (activation): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (classifier): Linear(in_features=480, out_features=4, bias=True)\n",
       "  )\n",
       "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=130048, out_features=32, bias=True)\n",
       "  (classifier): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dpo_classifier(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(Dpo_classifier, self).__init__()\n",
    "        self.max_length = 1024\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=5, stride=1)  # Convolutional layer\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=1)  # Convolutional layer\n",
    "        self.fc1 = nn.Linear(128 * (self.max_length - 2 * (5 - 1)), 32)  # calculate the output shape after 2 conv layers\n",
    "        self.classifier = nn.Linear(32, 1)  # Binary classification\n",
    "\n",
    "    def make_prediction(self, fasta_txt):\n",
    "        input_ids = tokenizer.encode(fasta_txt, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            outputs = self.pretrained_model(input_ids)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            token_probs, token_ids = torch.max(probs, dim=-1)\n",
    "            tokens = token_ids.view(1, -1) # ensure 2D shape\n",
    "            return tokens\n",
    "\n",
    "    def pad_or_truncate(self, tokens):\n",
    "        if tokens.size(1) < self.max_length:\n",
    "            tokens = F.pad(tokens, (0, self.max_length - tokens.size(1)))\n",
    "        elif tokens.size(1) > self.max_length:\n",
    "            tokens = tokens[:, :self.max_length]\n",
    "        return tokens\n",
    "\n",
    "    def forward(self, sequences):\n",
    "        batch_size = len(sequences)\n",
    "        tokens_batch = []\n",
    "        for seq in sequences:\n",
    "            tokens = self.make_prediction(seq)\n",
    "            tokens = self.pad_or_truncate(tokens)\n",
    "            tokens_batch.append(tokens)\n",
    "\n",
    "        outputs = torch.cat(tokens_batch).view(batch_size, 1, self.max_length)  # ensure 3D shape\n",
    "        outputs = outputs.float()  \n",
    "\n",
    "        out = F.relu(self.conv1(outputs))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view(batch_size, -1)  # Flatten the tensor\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.classifier(out)\n",
    "        return out, outputs\n",
    "\n",
    "model_classifier = Dpo_classifier(esm2_finetuned) # Create an instance of Dpo_classifier\n",
    "model_classifier.load_state_dict(torch.load(DpoDetection_path), strict = False) # Load the saved weights ; weird Error with some of the keys \n",
    "model_classifier.eval() # Set the model to evaluation mode for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(model, sequence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = [sequence]  # Wrap the sequence in a list to match the model's input format\n",
    "        outputs, sequence_outputs = model(sequence)\n",
    "        probas = torch.sigmoid(outputs)  # Apply sigmoid activation for binary classification\n",
    "        predictions = (probas > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        sequence_outputs_list = sequence_outputs.cpu().numpy().tolist()[0][0]\n",
    "        prob_predicted = probas[0].item()\n",
    "        return (predictions.item(), prob_predicted), sequence_outputs_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********************************************\n",
    "def get_labels(df) :\n",
    "    labels_df = []\n",
    "    for _,row in df.iterrows():\n",
    "        info = row[\"Boundaries\"]\n",
    "        seq_length = len(row[\"Full_seq\"])\n",
    "        if info == \"Negative\" :\n",
    "            label = 0\n",
    "            labels_df.append(label)         \n",
    "        else :\n",
    "            label = 1\n",
    "            labels_df.append(label)\n",
    "    return labels_df\n",
    "\n",
    "# Beta-helix :\n",
    "labels_beta_helix = get_labels(df_beta_helix)\n",
    "seq_beta_helix = df_beta_helix[\"Full_seq\"].to_list()\n",
    "\n",
    "# Beta propeller : \n",
    "labels_beta_propeller = get_labels(df_beta_prope)\n",
    "seq_beta_propeller = df_beta_prope[\"Full_seq\"].to_list()\n",
    "\n",
    "# Triple helix : \n",
    "labels_triple_helix = get_labels(df_beta_triple )\n",
    "seq_triple_helix = df_beta_triple[\"Full_seq\"].to_list()\n",
    "\n",
    "# Negative :\n",
    "labels_negative = get_labels(df_negative)\n",
    "seq_negative = df_negative[\"Full_seq\"].to_list()\n",
    "\n",
    "# The input data :\n",
    "sequences = seq_beta_helix + seq_beta_propeller + seq_triple_helix + seq_negative\n",
    "labels = labels_beta_helix + labels_beta_propeller + labels_triple_helix + labels_negative\n",
    "\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.2, random_state = 243)\n",
    "train_esm2 , train_CNV , esm2_labels , CNV_labels = train_test_split(train_sequences, train_labels, test_size=0.125, random_state = 243)\n",
    "\n",
    "train_sequences_PL16, test_sequences_PL16, train_labels_PL16, test_labels_PL16 = train_test_split(seq_pl16_interpro, labels_pl16, test_size=0.5, random_state = 243)\n",
    "\n",
    "train_CNV = train_CNV + train_sequences_PL16\n",
    "CNV_labels = CNV_labels + train_labels_PL16\n",
    "\n",
    "test_sequences = test_sequences + test_sequences_PL16\n",
    "test_labels = test_labels + test_labels_PL16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Make predictions on the test dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [06:23,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = []\n",
    "for _,seq in tqdm(enumerate(test_sequences)) : \n",
    "    prediction, sequence_outputs = predict_sequence(model_classifier, seq)\n",
    "    predicted_labels.append(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get right format : concatenate the test labels and the predicted labels then input it into the metric calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels) , len(predicted_labels)\n",
    "\n",
    "\n",
    "test_labels[35] = 1.0\n",
    "#test_labels.pop(24)\n",
    "#predicted_labels.pop(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mtest_labels\u001b[49m,predicted_labels))) : \n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m labels[\u001b[38;5;241m1\u001b[39m] : \n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i , labels[\u001b[38;5;241m0\u001b[39m], labels[\u001b[38;5;241m1\u001b[39m], sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "for i, labels in enumerate(list(zip(test_labels,predicted_labels))) : \n",
    "    if labels[0] != labels[1] : \n",
    "        print(i , labels[0], labels[1], sep = \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MTETIPLRVQFKRMKAAEWASSDVVLLEGEIGFETDTGFAKFGDGQNTFSKLKYLTGPKGPKGDTGLQGKTGGTGPRGPAGKPGTTDYNQLQNKPNLDAFARKQETDSKITELKSNKADKNAVYLKAESNAKLDEKLSLTGGIVTGQLQFKPNKSGIKPSSSVGGAINIDMSKSEGAGVVVYSNNDTSDGPLMILRSDKDTFNQSVQFVDYRGKTNAVNIVMRQPSTPNFSSALNITSANEGGSAMQLRGSEGALGTLKITHENPSLKANYDKNAAALSIDIVKKTNGAGTAAQGIYINSTSGTTGKLLRIRNLGDDKLHQLSAKITTTSSGTTETYENKLNSLRAEFTRSHQGLLTKLESQITGLRTVQQTTANQISQEIRNREGAVSRVQQDLDSYQRRLQNAEGSYSSLQQTVSGLQSDVNSPNSKFNSRISQLASQIDQRVTRADVTSIINQSGDSIKLAIQRAGGIDAKMSAKEIVSAINLNGYGVRISGERIALDGNTTVNGAFGAKLGEFIKLRADNIIGGTIDANKINVINLKASSIRGLDAEFIKARIEHTITSLLEGKVIRARNGAMMIDLNNSTIDFNSDASINFNSNNNALVRKSGTHTAFVHFSNATPKNFAGSALYASIGITSSGDRINSASSGRFCGARFFRTASGYEHTASIDQAEIYGDTVYLSDDFNINRGFRFRPAMMPGLLDMNDLYSAIIALGRCWQHLANANWNTARSNFINAVNSELNNHITKI'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences[468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [491, 492]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(test_labels, predicted_labels,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(test_labels, predicted_labels,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m )  \u001b[38;5;66;03m# Calculate recall\u001b[39;00m\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1238\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1071\u001b[0m     {\n\u001b[1;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1096\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1097\u001b[0m ):\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1411\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1251\u001b[0m     {\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1279\u001b[0m ):\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1281\u001b[0m \n\u001b[1;32m   1282\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;124;03m    0.38...\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1411\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[1;32m   1564\u001b[0m \n\u001b[1;32m   1565\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[0;32m-> 1721\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1499\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1499\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/concha-eloko/Linux/conda_envs/ML_work/lib/python3.11/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [491, 492]"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(test_labels, predicted_labels,average=\"binary\" )\n",
    "precision = precision_score(test_labels, predicted_labels,average=\"binary\")\n",
    "recall = recall_score(test_labels, predicted_labels,average=\"binary\" )  # Calculate recall\n",
    "mcc = matthews_corrcoef(test_labels, predicted_labels)  # Calculate MCC\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "cm = confusion_matrix(test_labels, predicted_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.97059, 0.9878, 0.98507, 0.97508)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(precision,5) , round(recall,5) , round(accuracy,5) , round(f1,5) , round(mcc,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[288,   0],\n",
       "       [  6, 198]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MRQNRERKLAEKAVRLAQSPDPRLRKKKMSMGFDPGSPEGDYSATVPVENSPTGNIELRMFSQLQQLADIRSIQEKIAKKAEWLPEYAGYIEGCLVTSPAPQNNVLVRLMIWAADVGDYEQAVRIAEFALLNEMVMPEGHTRSIAEFITEQCSQDFIKDHELAVKNASVIEKIIEIGTGESMVDEVRAKGFRALGDALRDAQPVEALNAYKNALRFNTNAGCVKQVTQLEKKLNLQPTESSPDATVGSQADASSVSTENESVPASTDTTPE'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_negative[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_work}/T30_eval.binary_classification.metrics.2008.txt\", \"w\") as outfile :\n",
    "    outfile.write(f\"F1 : {round(f1,5)},precision : {round(precision,5)},recall : {round(recall,5)},accuracy : {round(accuracy,5)},mcc : {round(mcc,5)},cm : {cm}\\n\")\n",
    "    for i, labels in enumerate(list(zip(test_labels,predicted_labels))) : \n",
    "        if labels[0] != labels[1] : \n",
    "            outfile.write(f\"{i}\\t{labels[0]}\\t{labels[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=big_pred__\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=5\n",
    "#SBATCH --mem=10gb \n",
    "#SBATCH --time=0-01:00:00 \n",
    "#SBATCH --output=big_pred__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/PhageDepo_pdb/script_files/Metrics.T30.binary_class.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_work",
   "language": "python",
   "name": "ml_work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
