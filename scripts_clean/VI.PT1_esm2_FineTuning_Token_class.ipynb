{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning the model for token classification \n",
    "***\n",
    "#### We will be predicting 2 depolymerase folds : Beta-helix and 6\n",
    "#### Here are the results for the models :\n",
    "***\n",
    "esm2_t6_8M_UR50D : {'eval_loss': 0.45753657817840576, <b>'eval_accuracy': 0.8439131075453115</b>, 'eval_runtime': 40.7606, 'eval_samples_per_second': 4.293, 'eval_steps_per_second': 0.54, 'epoch': 3.0}<br>\n",
    "esm2_t12_35M_UR50D : {'eval_loss': 0.35650020837783813, <b>'eval_accuracy': 0.9001007034209102</b>, 'eval_runtime': 83.4518, 'eval_samples_per_second': 2.097, 'eval_steps_per_second': 0.264, 'epoch': 3.0}<br>\n",
    "esm2_t30_150M_UR50D : {'eval_loss': 0.2777683734893799, <b>'eval_accuracy': 0.9233610987968299</b>, 'eval_runtime': 219.8341, 'eval_samples_per_second': 0.796, 'eval_steps_per_second': 0.1, 'epoch': 3.0}\n",
    "***\n",
    "\n",
    "#### The model model that work also for full beta-helix is esm2_t30_150M_UR50D checkpoint-192\n",
    "\n",
    "***\n",
    "#### Next step, generate another classical ML model to predict the probability of the protein actually carrying a depolymerase :\n",
    "Generate a probability/ score based on :\n",
    "1. Length of the largest consecutive positive token\n",
    "2. Span of the first predicted amino acid (followed by two consecutive predictions) to the last predicted one \n",
    "3. Total number of predicted amino acid\n",
    "4. Fraction of the total number of predicted amino acid within the largest consecutive positive token\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>Update 0407</b> : add a new class of dpo which fold is names \"triple helix\". Try applying the label \"1\" on it VS label \"3\". See what yields the best score.\n",
    "</div>\n",
    "Potential issues : Not enough sequences (n=30) , not the right label (\"3\" or \"1\")\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "Increasing the n of epoch allowed the model to converge towards optimal efficiency.<br>\n",
    "3 labels worked better than 4 labels\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<b>facebook/esm2_t12_35M_UR50D\t4 labels</b>  : {'eval_loss': 0.31591448187828064, <b>'eval_accuracy': 0.9166098962781013</b>, 'eval_runtime': 63.1028, 'eval_samples_per_second': 2.314, 'eval_steps_per_second': 0.586, 'epoch': 5.0}<br>\n",
    "<b>facebook/esm2_t30_150M_UR50D 4 labels</b> : {'eval_loss': 0.27637672424316406, <b>'eval_accuracy': 0.9289106801892133</b>, 'eval_runtime': 149.5283, 'eval_samples_per_second': 0.976, 'eval_steps_per_second': 0.247, 'epoch': 5.0}<br>\n",
    "    \n",
    "<b>facebook/esm2_t12_35M_UR50D\t3 labels</b> : {'eval_loss': 0.279034823179245, <b>'eval_accuracy': 0.9167922011878604</b>, 'eval_runtime': 59.9079, 'eval_samples_per_second': 2.437, 'eval_steps_per_second': 0.618, 'epoch': 5.0}<br>\n",
    "<b>facebook/esm2_t30_150M_UR50D 3 labels</b> : {'eval_loss': 0.25093308091163635, <b>'eval_accuracy': 0.9301484345765249</b>, 'eval_runtime': 175.1032, 'eval_samples_per_second': 0.834, 'eval_steps_per_second': 0.211, 'epoch': 5.0}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>Update 1807</b> : Based on the t-SNE results, 4 labels seem more reasonable despite the score being slightly higher for the 3 labels on the 0407. \n",
    "Added the PL_16 domains in the esm2 finetuning. Added in the CNV training proteins in Interproscan that present homology with the PL16 domain.<br>    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> facebook/esm2_t12_35M_UR50D 4 labels </b> : {'eval_loss': 0.34807953238487244, 'eval_accuracy': 0.9120480978760273, 'eval_runtime': 60.1534, 'eval_samples_per_second': 2.926, 'eval_steps_per_second': 0.731, 'epoch': 20.0}\n",
    "<br>\n",
    "<b>facebook/esm2_t30_150M_UR50D 4 labels</b> : \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<b>Update 1907</b> : \n",
    "Include some negative samples in the token classification task <br> Compute the MCC and compare across the different Methods\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "/media/concha-eloko/Linux/depolymerase_building/Phagedepo.Dataset.2007.tsv \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from Bio import SeqIO\n",
    "\n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "#path_work = \"/home/conchae/PhageDepo_pdb\"\n",
    "\n",
    "#df_depo = pd.read_csv(f\"{path_work}/Dpo_domains.phagedepo.0805.final.tsv\" , sep = \"\\t\" , header = 0)\n",
    "#info_PL16 = pd.read_csv(f\"{path_work}/PL_16.dpo_domain.tsv\", sep = \"\\t\", header = 0)\n",
    "\n",
    "df_depo = pd.read_csv(f\"{path_work}/Phagedepo.Dataset.2007.tsv\" , sep = \"\\t\" , header = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq_ID</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Boundaries</th>\n",
       "      <th>Full_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MF417929_00038</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MRQNRERKLAEKAVRLAQSPDPRLRKKKMSMGFDPGSPEGDYSATV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MF417929_00041</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MNTPQPIQFDLMNPRQHGRILFAMGMSVSEIAKQIDEKRATVESWK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MH616963_00015</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MAKDNYPFLDYINEDKSHYKTAASAGYKDDENLFLIGESGGFLMNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MH552500_00058</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MVKLEANVEEVINNYPFLNYINEDKSQYKTATNAGYDDPDNLFLIG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BK010471_00079</td>\n",
       "      <td>Negative</td>\n",
       "      <td>manual</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MADGKYPFLEYIEEPDKEKKYKKASDCGWYDPHNNFLIGDSGGFLL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>phagedepo__4646</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4646_A_5_379_783</td>\n",
       "      <td>MSVGLYGDGVSESQENINVTQYGWTNEDVAGITLIQDYLNQIQTLF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>phagedepo__6447</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6447_A_5_337_699</td>\n",
       "      <td>MGYFQMTRNVEELFGGVITAPHQIPFTYKSNVGGETFLSLPFYPVT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>phagedepo__1994</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1994_A_5_283_679</td>\n",
       "      <td>MSDCKSYVSKEDLQALKESQQHIEHVARSRNAAGEKALQVTDAIRG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>phagedepo__4581</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>0.872</td>\n",
       "      <td>full_protein</td>\n",
       "      <td>MLQVKDFSGATHAEQIQNAINAASTSALHKTVQLEENKDYSITAPI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>phagedepo__4247</td>\n",
       "      <td>right-handed beta-helix</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4247_A_5_297_677</td>\n",
       "      <td>MGYFQMTRNVEELFGGVITAPHQIPFTYKSNVGGETFLSLPFYPVT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2295 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Seq_ID                     Fold    Prob        Boundaries  \\\n",
       "0      MF417929_00038                 Negative  manual          Negative   \n",
       "1      MF417929_00041                 Negative  manual          Negative   \n",
       "2      MH616963_00015                 Negative  manual          Negative   \n",
       "3      MH552500_00058                 Negative  manual          Negative   \n",
       "4      BK010471_00079                 Negative  manual          Negative   \n",
       "...               ...                      ...     ...               ...   \n",
       "2290  phagedepo__4646  right-handed beta-helix     1.0  4646_A_5_379_783   \n",
       "2291  phagedepo__6447  right-handed beta-helix     1.0  6447_A_5_337_699   \n",
       "2292  phagedepo__1994  right-handed beta-helix     1.0  1994_A_5_283_679   \n",
       "2293  phagedepo__4581  right-handed beta-helix   0.872      full_protein   \n",
       "2294  phagedepo__4247  right-handed beta-helix     1.0  4247_A_5_297_677   \n",
       "\n",
       "                                               Full_seq  \n",
       "0     MRQNRERKLAEKAVRLAQSPDPRLRKKKMSMGFDPGSPEGDYSATV...  \n",
       "1     MNTPQPIQFDLMNPRQHGRILFAMGMSVSEIAKQIDEKRATVESWK...  \n",
       "2     MAKDNYPFLDYINEDKSHYKTAASAGYKDDENLFLIGESGGFLMNI...  \n",
       "3     MVKLEANVEEVINNYPFLNYINEDKSQYKTATNAGYDDPDNLFLIG...  \n",
       "4     MADGKYPFLEYIEEPDKEKKYKKASDCGWYDPHNNFLIGDSGGFLL...  \n",
       "...                                                 ...  \n",
       "2290  MSVGLYGDGVSESQENINVTQYGWTNEDVAGITLIQDYLNQIQTLF...  \n",
       "2291  MGYFQMTRNVEELFGGVITAPHQIPFTYKSNVGGETFLSLPFYPVT...  \n",
       "2292  MSDCKSYVSKEDLQALKESQQHIEHVARSRNAAGEKALQVTDAIRG...  \n",
       "2293  MLQVKDFSGATHAEQIQNAINAASTSALHKTVQLEENKDYSITAPI...  \n",
       "2294  MGYFQMTRNVEELFGGVITAPHQIPFTYKSNVGGETFLSLPFYPVT...  \n",
       "\n",
       "[2295 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_depo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create the Dpo_domains.phagedepo.0407.final.tsv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "info_PL16_1607 = pd.read_csv(f\"{path_work}/PL_16.proteins.boundaries.tsv\", sep = \"\\t\", header = 0)\n",
    "fasta_PL16 = SeqIO.parse(f\"{path_work}/PL16.index.multi.fasta\" , \"fasta\")\n",
    "info_PL16 = pd.read_csv(f\"{path_work}/PL_16.dpo_domain.tsv\", sep = \"\\t\", header = 0)\n",
    "\n",
    "\n",
    "sequences = set()\n",
    "\n",
    "with open(f\"{path_work}/Dpo_domains.phagedepo.1607.final.tsv\", \"w\") as outfile :\n",
    "    outfile.write(\"Seq_ID\\tFold\\tProb\\tBoundaries\\tFull_seq\\n\")\n",
    "    for _,row in info_PL16_1607.iterrows() :\n",
    "        Seq_ID = row[\"protein_fasta\"] \n",
    "        Fold = \"triple-helix\"\n",
    "        Prob = \"manual\"\n",
    "        Boundaries = row[\"boundaries\"] \n",
    "        for record in fasta_PL16 :\n",
    "            if record.description == Seq_ID :\n",
    "                Full_seq = record.seq\n",
    "                sequences.add(Full_seq)\n",
    "                break\n",
    "        outfile.write(f\"{Seq_ID}\\t{Fold}\\t{Prob}\\t{Boundaries}\\t{Full_seq}\\n\")\n",
    "\n",
    "with open(f\"{path_work}/Dpo_domains.phagedepo.1607.final.tsv\", \"a+\") as outfile :\n",
    "    for _,row in info_PL16.iterrows() :\n",
    "        Seq_ID = row[\"protein_fasta\"].split(\".fa\")[0]\n",
    "        Fold = \"triple-helix\"\n",
    "        Prob = \"manual\"\n",
    "        Boundaries = row[\"boundaries\"] \n",
    "        prot_parse = SeqIO.parse(f\"{path_work}/0407_dpos/{row['protein_fasta']}\" , \"fasta\")\n",
    "        for record in prot_parse :\n",
    "            Full_seq = record.seq\n",
    "            break\n",
    "        if Full_seq not in sequences :\n",
    "            sequences.add(Full_seq)\n",
    "            outfile.write(f\"{Seq_ID}\\t{Fold}\\t{Prob}\\t{Boundaries}\\t{Full_seq}\\n\")\n",
    "        \n",
    "\n",
    "with open(f\"{path_work}/Dpo_domains.phagedepo.1607.final.tsv\", \"a+\") as outfile :\n",
    "    for _,row in df_depo.iterrows() :\n",
    "        outfile.write(f\"{row['Seq_ID']}\\t{row['Fold']}\\t{row['Prob']}\\t{row['Boundaries']}\\t{row['Full_seq']}\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "with open(f\"{path_work}/Dpo_domains.phagedepo.0407.final.tsv\", \"w\") as outfile :\n",
    "    outfile.write(\"Seq_ID\\tFold\\tProb\\tBoundaries\\tFull_seq\\n\")\n",
    "    for _,row in info_PL16.iterrows() :\n",
    "        Seq_ID = row[\"protein_fasta\"].split(\".fa\")[0]\n",
    "        Fold = \"triple-helix\"\n",
    "        Prob = \"manual\"\n",
    "        Boundaries = row[\"boundaries\"] \n",
    "        prot_parse = SeqIO.parse(f\"{path_work}/0407_dpos/{row['protein_fasta']}\" , \"fasta\")\n",
    "        for record in prot_parse :\n",
    "            Full_seq = record.seq\n",
    "            break\n",
    "        outfile.write(f\"{Seq_ID}\\t{Fold}\\t{Prob}\\t{Boundaries}\\t{Full_seq}\\n\")\n",
    "        \n",
    "with open(f\"{path_work}/Dpo_domains.phagedepo.0407.final.tsv\", \"a+\") as outfile :\n",
    "    for _,row in df_depo.iterrows() :\n",
    "        outfile.write(f\"{row['Seq_ID']}\\t{row['Fold']}\\t{row['Prob']}\\t{row['Boundaries']}\\t{row['Full_seq']}\\n\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_beta_helix = df_depo[df_depo[\"Fold\"] == \"right-handed beta-helix\"]\n",
    "df_beta_prope = df_depo[df_depo[\"Fold\"] == \"6-bladed beta-propeller\"]\n",
    "df_beta_triple =  df_depo[df_depo[\"Fold\"] == \"triple-helix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seq_ID</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Boundaries</th>\n",
       "      <th>Full_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rcsb_pdb_2YW0</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>104:308</td>\n",
       "      <td>MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MGYP001296033211</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>37:260</td>\n",
       "      <td>GNTLYYTSDGLQAGTTIYTDGSVIGVGTTLPKAKLHLMSNSVDRTS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGYP001613371361</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>ASSSTSVGGAILLENTGNTGAGFIIYSNAGASSGRLMNIRADNIAF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MGYP001566598439</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>DPTITFNSGAVAVGGALSANNLISTTIANTVNSQGLTVTQNDTTNN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGYP001559216884</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>AIGSLVPTELLSLTGNFSITNPNAGKTFIIDPNGAAPTSTSTGGAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rcsb_pdb_2YX2</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>104:297</td>\n",
       "      <td>MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MGYP001585967839</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>DGTGAGLGITSTSDAALSLSNSGNGNHTAIINYTGTGSAQAALNIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MGYP000559111392</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>MYIDQNANTSASTSVGGAVLLDNSGNAGAGLVVYSTQGASGTGHLI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MGYP000616189667</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>RDLVKITNDDAAAVAATALSIQSDGGRGIFIDSNLAAGLPSLEIDS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MGYP000201891019</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>EQYGMGRAGHFEIVNASNNTDALHAATNGNGAAIRGFSTGNGTAGE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MGYP001479054291</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>TGGKGMFITSSSNNLIEGGAVVEINQSGSTMTAANAAVLSVIQAGS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MGYP000906719155</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>ATYFVGSGQYLTGVNATDNTKVAKSGDAMTGPLEINYSTATESLYV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MGYP003587387663</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>KDLIDTNNANLLHKTGNESWSGIKSTSNSGGFTNALQLENNSTFAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rcsb_pdb_2C3F</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>104:303</td>\n",
       "      <td>MGSSHHHHHHSSGLVPRGSHMSSENIPLRVQFKRMKAAEWARSDVI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rcsb_pdb_3EKA</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>104:308</td>\n",
       "      <td>LRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGHNRFSDL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MGYP003142855628</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>ASATSGNTLKVYRDLASGSTDADMVYFHQDNASDNTIALQVQQDSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rcsb_pdb_2YVV</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>104:308</td>\n",
       "      <td>MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MGYP001412872376</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>KLHVNVGSTDGTTGIWVDLNDADQQGIRIDANTAGCTANVFELRAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A0A077PJH0</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>MAFRSKTHKGQGYNELLFEDAKGSELLSLHAQKDMHTKVLNNRDTH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A0A0E1ETG8</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>107:307</td>\n",
       "      <td>MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A0A182DVL8</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>full</td>\n",
       "      <td>AGENGATTTFDGPVAAERFSADTTLEAAFLKTTSETNHAATIYQAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q1CPE4</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>104:304</td>\n",
       "      <td>MTETIPLRVQFKRMTAEEWTRSDVILLESEIGFETDTGYAKFGDGK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A0A0H3BZL2</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>100:304</td>\n",
       "      <td>MTETIPLRVQFKRMTAKEWASSAVILLEGEIGFETDTGYAKFGDGK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A0A7K2KMZ9</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>38:246</td>\n",
       "      <td>MTVGRRIFLGGFTAGAVTLAAAGTAAAAPEAAPGDPTVFDGPVVAK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A0A7G3UKD1</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>35:245</td>\n",
       "      <td>MAVNRRLFLGGFTAGAVTVAAGTATPAAAAAAQGPTTTFDGPVVAE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A0A1D3DNL6</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>33:247</td>\n",
       "      <td>MSVTRRLFLGGFTAGAVTVAAGGDAVAAETAEAAGEPTTFDGPVVA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A0A0K8PG78</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>100:360</td>\n",
       "      <td>MRIRVIGERPVDSITVNGGQTGRIVHVNAGLVSSVNGRTGGVTLTA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A0A7Z6TP65</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>41:226</td>\n",
       "      <td>MTVGRRVFLGAFTAGAVTVATGSEAAADGEYTLYTSPAQFYGSSTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A0A1D8G892</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>42:252</td>\n",
       "      <td>MGVTRRLFLGGFTAGAVTVAAGGDAVAAEAGGDAVAAEAAGETTVF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A0A5C4XFE5</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>61:292</td>\n",
       "      <td>MKGDTGTAGAKGDTGDTGPAGPGVAAGGTTNQFLIKSSSTNYATTW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A0A1G9HV85</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>30:302</td>\n",
       "      <td>MTSRRLFLGAFTAGAVTVAAGASEAAAAEAEGVVEGDTTFTGAVKA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A0A6B3B193</td>\n",
       "      <td>triple-helix</td>\n",
       "      <td>manual</td>\n",
       "      <td>183:388</td>\n",
       "      <td>MPEGIPTVTVRGRFLALDGKPRRGQVEFRVPDTVTFDAHDVILSGP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Seq_ID          Fold    Prob Boundaries  \\\n",
       "0      rcsb_pdb_2YW0  triple-helix  manual    104:308   \n",
       "1   MGYP001296033211  triple-helix  manual     37:260   \n",
       "2   MGYP001613371361  triple-helix  manual       full   \n",
       "3   MGYP001566598439  triple-helix  manual       full   \n",
       "4   MGYP001559216884  triple-helix  manual       full   \n",
       "5      rcsb_pdb_2YX2  triple-helix  manual    104:297   \n",
       "6   MGYP001585967839  triple-helix  manual       full   \n",
       "7   MGYP000559111392  triple-helix  manual       full   \n",
       "8   MGYP000616189667  triple-helix  manual       full   \n",
       "9   MGYP000201891019  triple-helix  manual       full   \n",
       "10  MGYP001479054291  triple-helix  manual       full   \n",
       "11  MGYP000906719155  triple-helix  manual       full   \n",
       "12  MGYP003587387663  triple-helix  manual       full   \n",
       "13     rcsb_pdb_2C3F  triple-helix  manual    104:303   \n",
       "14     rcsb_pdb_3EKA  triple-helix  manual    104:308   \n",
       "15  MGYP003142855628  triple-helix  manual       full   \n",
       "16     rcsb_pdb_2YVV  triple-helix  manual    104:308   \n",
       "17  MGYP001412872376  triple-helix  manual       full   \n",
       "18        A0A077PJH0  triple-helix  manual       full   \n",
       "19        A0A0E1ETG8  triple-helix  manual    107:307   \n",
       "20        A0A182DVL8  triple-helix  manual       full   \n",
       "21            Q1CPE4  triple-helix  manual    104:304   \n",
       "22        A0A0H3BZL2  triple-helix  manual    100:304   \n",
       "23        A0A7K2KMZ9  triple-helix  manual     38:246   \n",
       "24        A0A7G3UKD1  triple-helix  manual     35:245   \n",
       "25        A0A1D3DNL6  triple-helix  manual     33:247   \n",
       "26        A0A0K8PG78  triple-helix  manual    100:360   \n",
       "27        A0A7Z6TP65  triple-helix  manual     41:226   \n",
       "28        A0A1D8G892  triple-helix  manual     42:252   \n",
       "29        A0A5C4XFE5  triple-helix  manual     61:292   \n",
       "30        A0A1G9HV85  triple-helix  manual     30:302   \n",
       "31        A0A6B3B193  triple-helix  manual    183:388   \n",
       "\n",
       "                                             Full_seq  \n",
       "0   MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "1   GNTLYYTSDGLQAGTTIYTDGSVIGVGTTLPKAKLHLMSNSVDRTS...  \n",
       "2   ASSSTSVGGAILLENTGNTGAGFIIYSNAGASSGRLMNIRADNIAF...  \n",
       "3   DPTITFNSGAVAVGGALSANNLISTTIANTVNSQGLTVTQNDTTNN...  \n",
       "4   AIGSLVPTELLSLTGNFSITNPNAGKTFIIDPNGAAPTSTSTGGAI...  \n",
       "5   MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "6   DGTGAGLGITSTSDAALSLSNSGNGNHTAIINYTGTGSAQAALNIT...  \n",
       "7   MYIDQNANTSASTSVGGAVLLDNSGNAGAGLVVYSTQGASGTGHLI...  \n",
       "8   RDLVKITNDDAAAVAATALSIQSDGGRGIFIDSNLAAGLPSLEIDS...  \n",
       "9   EQYGMGRAGHFEIVNASNNTDALHAATNGNGAAIRGFSTGNGTAGE...  \n",
       "10  TGGKGMFITSSSNNLIEGGAVVEINQSGSTMTAANAAVLSVIQAGS...  \n",
       "11  ATYFVGSGQYLTGVNATDNTKVAKSGDAMTGPLEINYSTATESLYV...  \n",
       "12  KDLIDTNNANLLHKTGNESWSGIKSTSNSGGFTNALQLENNSTFAT...  \n",
       "13  MGSSHHHHHHSSGLVPRGSHMSSENIPLRVQFKRMKAAEWARSDVI...  \n",
       "14  LRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGHNRFSDL...  \n",
       "15  ASATSGNTLKVYRDLASGSTDADMVYFHQDNASDNTIALQVQQDSS...  \n",
       "16  MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "17  KLHVNVGSTDGTTGIWVDLNDADQQGIRIDANTAGCTANVFELRAN...  \n",
       "18  MAFRSKTHKGQGYNELLFEDAKGSELLSLHAQKDMHTKVLNNRDTH...  \n",
       "19  MSENIPLRVQFKRMKAAEWARSDVILLESEIGFETDTGFARAGDGH...  \n",
       "20  AGENGATTTFDGPVAAERFSADTTLEAAFLKTTSETNHAATIYQAG...  \n",
       "21  MTETIPLRVQFKRMTAEEWTRSDVILLESEIGFETDTGYAKFGDGK...  \n",
       "22  MTETIPLRVQFKRMTAKEWASSAVILLEGEIGFETDTGYAKFGDGK...  \n",
       "23  MTVGRRIFLGGFTAGAVTLAAAGTAAAAPEAAPGDPTVFDGPVVAK...  \n",
       "24  MAVNRRLFLGGFTAGAVTVAAGTATPAAAAAAQGPTTTFDGPVVAE...  \n",
       "25  MSVTRRLFLGGFTAGAVTVAAGGDAVAAETAEAAGEPTTFDGPVVA...  \n",
       "26  MRIRVIGERPVDSITVNGGQTGRIVHVNAGLVSSVNGRTGGVTLTA...  \n",
       "27  MTVGRRVFLGAFTAGAVTVATGSEAAADGEYTLYTSPAQFYGSSTT...  \n",
       "28  MGVTRRLFLGGFTAGAVTVAAGGDAVAAEAGGDAVAAEAAGETTVF...  \n",
       "29  MKGDTGTAGAKGDTGDTGPAGPGVAAGGTTNQFLIKSSSTNYATTW...  \n",
       "30  MTSRRLFLGAFTAGAVTVAAGASEAAAAEAEGVVEGDTTFTGAVKA...  \n",
       "31  MPEGIPTVTVRGRFLALDGKPRRGQVEFRVPDTVTFDAHDVILSGP...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_beta_triple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create the negative dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/databases/Millard_jan_2023/5Jan2023_vConTACT2_proteins.faa \\\n",
    "/media/concha-eloko/Linux/Databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "#path_mill_db = \"/home/conchae/databases/Millard_jan_2023/5Jan2023_vConTACT2_proteins.faa\"\n",
    "path_mill_db = \"/media/concha-eloko/Linux/Databases/5Jan2023_vConTACT2_proteins.faa\"\n",
    "\n",
    "proteins_annot = {record.id : \" \".join(record.description.split(\" \")[1:]) for record in SeqIO.parse(path_mill_db, \"fasta\")}\n",
    "proteins_seq = {record.id : record.seq for record in SeqIO.parse(path_mill_db, \"fasta\")}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a relevant file for the negative sequences : \n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "\n",
    "negative_annotation = {\"terminase\" : [], \"helicase\" : [], \"DNA polymerase\" : [], \"RNaseH\" : [],\n",
    "                       \"methyltransferase\" : [] , \"endolysin\" : [], \"major head protein\" : [], \"major tail\" :[],\n",
    "                      \"lysozyme\" : [] , \"cytidylyltransferase\" : [], \"exonuclease\" : [], \"endonuclease\" : [], \n",
    "                      \"exopolyphosphatase\" : [] , \"ribosyltransferase\" : [], \"minor tail\" : []}\n",
    "\n",
    "with open(f\"{path_work}/negative_sequences.multi.test.tsv\",\"w\") as outfile :\n",
    "    track_sequences = set()\n",
    "    for prot_id,description in proteins_annot.items() :\n",
    "        for neg_annot in negative_annotation :\n",
    "            if description.lower().count(neg_annot.lower()) > 0 :\n",
    "                if len(negative_annotation[neg_annot]) < 100 and len(str(proteins_seq[prot_id])) > 200 and str(proteins_seq[prot_id]) not in track_sequences:\n",
    "                    track_sequences.add(str(proteins_seq[prot_id]))\n",
    "                    a = (prot_id , str(proteins_seq[prot_id]))\n",
    "                    negative_annotation[neg_annot].append(a)\n",
    "                    break\n",
    "                else :\n",
    "                    break\n",
    "    for neg_annot in negative_annotation :\n",
    "        for _,tup_neg in enumerate(negative_annotation[neg_annot]) :\n",
    "            outfile.write(f\"{neg_annot}\\t{tup_neg[0]}\\t{tup_neg[1]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create the 1907 dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_depo = pd.read_csv(f\"{path_work}/Dpo_domains.phagedepo.1607.final.tsv\" , sep = \"\\t\" , header = 0)\n",
    "df_neg = pd.read_csv(f\"{path_work}/negative_sequences.multi.test.tsv\", sep = \"\\t\", names = [\"annotation\", \"prot_id\",\"sequence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{path_work}/Phagedepo.Dataset.2007.tsv\", \"w\") as outfile :\n",
    "    outfile.write(f\"Seq_ID\\tFold\\tProb\\tBoundaries\\tFull_seq\\n\")\n",
    "    for _,row in df_neg.iterrows() :\n",
    "        Seq_ID = row[\"prot_id\"] \n",
    "        Fold = \"Negative\"\n",
    "        Prob = \"manual\"\n",
    "        Boundaries = \"Negative\"\n",
    "        Full_seq = row[\"sequence\"]\n",
    "        outfile.write(f\"{Seq_ID}\\t{Fold}\\t{Prob}\\t{Boundaries}\\t{Full_seq}\\n\")\n",
    "    for _,row in df_depo.iterrows() :\n",
    "        Seq_ID = row[\"Seq_ID\"] \n",
    "        Fold = row[\"Fold\"] \n",
    "        Prob = row[\"Prob\"] \n",
    "        Boundaries = row[\"Boundaries\"] \n",
    "        Full_seq = row[\"Full_seq\"] \n",
    "        outfile.write(f\"{Seq_ID}\\t{Fold}\\t{Prob}\\t{Boundaries}\\t{Full_seq}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "> Prepare the labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(df , label = 1) :\n",
    "    labels_df = []\n",
    "    for _,row in df.iterrows():\n",
    "        info = row[\"Boundaries\"]\n",
    "        seq_length = len(row[\"Full_seq\"])\n",
    "        if info == \"Negative\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        elif info == \"full_protein\" or info == \"full\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        elif info.count(\":\") > 0 : \n",
    "            start = int(info.split(\":\")[0])\n",
    "            end = int(info.split(\":\")[1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "        else :\n",
    "            start = int(info.split(\"_\")[-2])\n",
    "            end = int(info.split(\"_\")[-1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "    return labels_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beta_helix = df_depo[df_depo[\"Fold\"] == \"right-handed beta-helix\"]\n",
    "df_beta_prope = df_depo[df_depo[\"Fold\"] == \"6-bladed beta-propeller\"]\n",
    "df_beta_triple =  df_depo[df_depo[\"Fold\"] == \"triple-helix\"]\n",
    "df_negative = df_depo[df_depo[\"Fold\"] == \"Negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta-helix :\n",
    "labels_beta_helix = get_labels(df_beta_helix , label = 1)\n",
    "seq_beta_helix = df_beta_helix[\"Full_seq\"].to_list()\n",
    "\n",
    "# Beta propeller : \n",
    "labels_beta_propeller = get_labels(df_beta_prope , label = 2)\n",
    "seq_beta_propeller = df_beta_prope[\"Full_seq\"].to_list()\n",
    "\n",
    "# Triple helix : \n",
    "labels_triple_helix = get_labels(df_beta_triple , label = 1)\n",
    "seq_triple_helix = df_beta_triple[\"Full_seq\"].to_list()\n",
    "\n",
    "# Negative :\n",
    "labels_negative = get_labels(df_negative , label = 0)\n",
    "seq_negative = df_negative[\"Full_seq\"].to_list()\n",
    "\n",
    "# The input data :\n",
    "sequences = seq_beta_helix + seq_beta_propeller + seq_triple_helix + seq_negative\n",
    "labels = labels_beta_helix + labels_beta_propeller + labels_triple_helix + labels_negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# II. Fine-tuning ESM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.2, random_state = 243)\n",
    "train_esm2 , train_CNV , esm2_labels , CNV_labels = train_test_split(train_sequences, train_labels, test_size=0.25, random_state = 243)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSNIVAQPFPYFPDPDRGRALFNADIYIGLIDLDPFVPTNRIDVFY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAAFEGSMKSQLQGVSQQIARERLDGQVTAQDNMLSDVVTGLRRRP...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MTVSAQNRKNIFTTNGVTVYFPFTFSVNTADQVMALTRDSDGVETE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSRRLFLGAFTAGAVTVAAGASEAAAAEAEGVVEGDTTFTGAVKA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSLVQLIDSTVGLRNELTQPDGAYLTGLGASTVGALLDTTRKLSYY...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>MISQFNQPRGSTSIEVNKQSIARNFGVKEDEVVYFTVGIDLSGFKV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>MTTKVNNRMIDGATVNVLDFGADPSGQTDSTSQIQEAINTAKTQGV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>MTNPTLITTPFAENGDKNTIPESVGANPQNATMQAGFPPITQQKIS...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>MAADGTVTGTGTKWQSSLSLIRPGATIMFLSSPIQMAVVNKVVSDT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>MALVDLVRAGGHSIEYPQFSSMAKLKAFPHSEDGQLVRLLSWHEGV...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sequence  Label\n",
       "0    MSNIVAQPFPYFPDPDRGRALFNADIYIGLIDLDPFVPTNRIDVFY...      1\n",
       "1    MAAFEGSMKSQLQGVSQQIARERLDGQVTAQDNMLSDVVTGLRRRP...      1\n",
       "2    MTVSAQNRKNIFTTNGVTVYFPFTFSVNTADQVMALTRDSDGVETE...      1\n",
       "3    MTSRRLFLGAFTAGAVTVAAGASEAAAAEAEGVVEGDTTFTGAVKA...      1\n",
       "4    MSLVQLIDSTVGLRNELTQPDGAYLTGLGASTVGALLDTTRKLSYY...      1\n",
       "..                                                 ...    ...\n",
       "141  MISQFNQPRGSTSIEVNKQSIARNFGVKEDEVVYFTVGIDLSGFKV...      1\n",
       "142  MTTKVNNRMIDGATVNVLDFGADPSGQTDSTSQIQEAINTAKTQGV...      1\n",
       "143  MTNPTLITTPFAENGDKNTIPESVGANPQNATMQAGFPPITQQKIS...      1\n",
       "144  MAADGTVTGTGTKWQSSLSLIRPGATIMFLSSPIQMAVVNKVVSDT...      1\n",
       "145  MALVDLVRAGGHSIEYPQFSSMAKLKAFPHSEDGQLVRLLSWHEGV...      1\n",
       "\n",
       "[146 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_CNV_df = pd.DataFrame(train_CNV, columns = [\"sequence\"])\n",
    "train_CNV_df[\"Label\"] = 1\n",
    "train_CNV_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/concha-eloko/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Define the model :\n",
    "model_checkpoint = \"facebook/esm2_t6_8M_UR50D\"\n",
    "model_checkpoint = \"facebook/esm2_t12_35M_UR50D\"\n",
    "model_checkpoint = \"facebook/esm2_t30_150M_UR50D\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "train_tokenized = tokenizer(train_esm2)\n",
    "test_tokenized = tokenizer(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", esm2_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForTokenClassification: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing EsmForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForTokenClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = 3\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 4\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-depolymerase.0407.3_labels\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.001,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    logging_dir='./logs',\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/concha-eloko/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 523\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 786\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 1.96 GiB total capacity; 1.24 GiB already allocated; 66.38 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15413/2688807664.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         )\n\u001b[0;32m-> 1500\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1501\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                 if (\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2502\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2504\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 130.00 MiB (GPU 0; 1.96 GiB total capacity; 1.24 GiB already allocated; 66.38 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=FT_model\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=50gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=FT_model%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/PhageDepo_pdb/script_files/fine_tune.esm2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# III. Testing the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model :\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase \\\n",
    "/media/concha-eloko/Linux/depolymerase_building/ \n",
    "\n",
    "rsync -avzhe ssh \\\n",
    "conchae@garnatxa.srv.cpd:/home/conchae/PhageDepo_pdb/script_files/esm2_t12_35M_UR50D-finetuned-depolymerase.0407.3_labels \\\n",
    "/media/concha-eloko/Linux/depolymerase_building/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "from collections import Counter\n",
    "import torch\n",
    "path_work = \"/media/concha-eloko/Linux/depolymerase_building\"\n",
    "#path_work = \"/home/conchae/PhageDepo_pdb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /media/concha-eloko/Linux/depolymerase_building/esm2_t12_35M_UR50D-finetuned-depolymerase.0407.3_labels/checkpoint-550/ were not used when initializing EsmForTokenClassification: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "- This IS expected if you are initializing EsmForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EsmForTokenClassification(\n",
       "  (esm): EsmModel(\n",
       "    (embeddings): EsmEmbeddings(\n",
       "      (word_embeddings): Embedding(33, 480, padding_idx=1)\n",
       "      (position_embeddings): Embedding(1026, 480, padding_idx=1)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): EsmEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): EsmLayer(\n",
       "          (attention): EsmAttention(\n",
       "            (self): EsmSelfAttention(\n",
       "              (query): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (key): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (value): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (rotary_embeddings): RotaryEmbedding()\n",
       "            )\n",
       "            (output): EsmSelfOutput(\n",
       "              (dense): Linear(in_features=480, out_features=480, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (intermediate): EsmIntermediate(\n",
       "            (dense): Linear(in_features=480, out_features=1920, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): EsmOutput(\n",
       "            (dense): Linear(in_features=1920, out_features=480, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (emb_layer_norm_after): LayerNorm((480,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Linear(in_features=480, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "model_path = f\"{path_work}/esm2_t12_35M_UR50D-finetuned-depolymerase.0407.3_labels/checkpoint-550/\"\n",
    "#model_path = \"/home/conchae/PhageDepo_pdb/script_files/esm2_t30_150M_UR50D-finetuned-depolymerase/checkpoint-198\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 370, 1: 249}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode input text\n",
    "input_text = \"MTVKISGILKDALARPLANVAIRFLSLKTSSNIVIGVDTDFRTANDGSYDIDVVSGTYGVLMNFGSYEKIGEINVYNDSLPGTLEDFLTIPGIEEITPEILAQVIQARNNAVNAANNAASDATTIINEQLQNQKNEFDQFLLSSGYVFLGDYEDGPFQFSVRNQYIRYSNQYYRLDAATDVGFTTTGTDATSFASDVTHFVLMDGDTLRQNLGSSDGTSWVAKLGNKPLVAISYYKNQGLSDQDAVQAAFNESSNILIDHDIALTDYITFDRSEECYVYRKPGVTITGHGYLPKLRTNPAHVVETAIRHSKTSDRGGSYDRTYSHQSLAAEMVVHDVLSTDPGQENFVALYSGIESFNCQKQRMWAFNTVTSAHNLKTGDEIYGCEIDMNVDGTLDGGGQFVGVYIAGIGDVRTCANADGIRVQRLRDGVYKWQYGLRIFDSMTGINITDASTYSIFASGSAPIVRRKTTQDGGWSYTHSLSASSVKWGVDDYGDTYSRRLYLGTGDGKSKNRVNLDGGVSYYTTNAAVAWGSIAANAYVDKDITTLVGVSIADWTNYTIDVTPIGYAGAMPVVAVQAYINSTKTQAYVRIINISGAPLSSCNVGLNIKVSGHSATN\"  # Replace this with your input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt', truncation= True)\n",
    "\n",
    "# Get token classifications\n",
    "with torch.no_grad() :\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# The model returns logits which can be turned into probabilities using softmax\n",
    "import torch\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# the order of labels in model.config.id2label should match the order of probabilities in probs\n",
    "labels = model.config.id2label\n",
    "\n",
    "tokens = []\n",
    "for token_id, token_probs in zip(input_ids[0], probs[0]):\n",
    "    top_label_id = token_probs.argmax().item()\n",
    "    tokens.append(int(labels[top_label_id].split(\"_\")[1]))\n",
    "    #print(f\"{tokenizer.decode([token_id])}: {labels[top_label_id]}\")\n",
    "    \n",
    "\"\"\"with open(f\"{path_work}/output.token.txt\", \"w\") as outfile :\n",
    "    outfile.write(str(tokens))\"\"\"\n",
    "dict(Counter(tokens))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "tokens = np.array(tokens)  # convert your list to numpy array for convenience\n",
    "\n",
    "# create your plot\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# plot data\n",
    "for i in range(len(tokens) - 1):\n",
    "    if tokens[i] == 0:\n",
    "        color = 'black'\n",
    "    elif tokens[i] == 1:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "        #tokens[i] == 1\n",
    "    plt.plot([i, i+1], [tokens[i], tokens[i+1]], color=color, marker='o')\n",
    "\n",
    "plt.xlabel('Token')\n",
    "plt.ylabel('Label')\n",
    "plt.title('Label for each token')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.yticks(np.arange(2), ['0', '1'])  \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Test on Bea's phages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "path_work = \"/home/conchae/PhageDepo_pdb\"\n",
    "path_fasta = f\"{path_work}/Bea_phages_no_Dpo\"\n",
    "path_bea_out = f\"{path_fasta}/model_outputs\"\n",
    "model_path = f\"{path_work}/script_files/esm2_t12_35M_UR50D-finetuned-depolymerase/checkpoint-198/\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "def make_prediction(fasta_txt) :\n",
    "    if len(fasta_txt) > 200 :\n",
    "        input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "        outputs = model(input_ids)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        labels = model.config.id2label\n",
    "        tokens = []\n",
    "        for token_id, token_probs in zip(input_ids[0], probs[0]):\n",
    "            top_label_id = token_probs.argmax().item()\n",
    "            tokens.append(labels[top_label_id].split(\"_\")[1])\n",
    "        return tokens\n",
    "        \n",
    "for multifasta in os.listdir(path_fasta) :\n",
    "    if multifasta[-5:] == \"fasta\" :\n",
    "        fastas = SeqIO.parse(f\"{path_fasta}/{multifasta}\" , \"fasta\")\n",
    "        for record in fastas :\n",
    "            locus_tag = record.description.split(\"locus_tag=\")[1].split(\"]\")[0]\n",
    "            annotation = \"_\".join(record.description.split(\"protein=\")[1].split(\"]\")[0].split())\n",
    "            sequence = record.seq\n",
    "            results = make_prediction(sequence)\n",
    "            if \"1\" in dict(Counter(tokens)) :\n",
    "                n_depo = dict(Counter(tokens))[\"1\"]\n",
    "            elif \"2\" in dict(Counter(tokens)) :\n",
    "                n_depo = dict(Counter(tokens))[\"1\"]\n",
    "            else : \n",
    "                n_depo = 0\n",
    "            with open(f\"{path_bea_out}/{locus_tag}.{annotation}__{n_depo}.out\" , \"w\") as outfile :\n",
    "                outfile.write(str(results))\n",
    "            \n",
    "# ************************************************************* \n",
    "#!/bin/bash\n",
    "#BATCH --job-name=bea_pred\n",
    "#SBATCH --qos=short \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem=100gb \n",
    "#SBATCH --time=1-00:00:00 \n",
    "#SBATCH --output=bea_pred%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/PhageDepo_pdb/script_files/beas_phages.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Bea's data insights : \n",
    "#### Add more sequences for 6 bladed-beta propeller ==> That was the missing fold in Bea's searching.\n",
    "#### Need to add negative data.\n",
    "#### The annotations : terminase large subunit , helicase , DNA , polymerase , RNaseH , methyltransferase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Try to improve further the performance of the model using bayesian search :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from transformers import IntervalStrategy, AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import TrainerCallback, TrainerState, TrainerControl\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "import logging\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "path_work = \"/home/conchae/PhageDepo_pdb\"\n",
    "\n",
    "# ******************************************************************\n",
    "# LOAD THE DATA :\n",
    "df_depo = pd.read_csv(f\"{path_work}/Dpo_domains.phagedepo.0805.final.tsv\" , sep = \"\\t\" , header = 0)\n",
    "\n",
    "df_beta_helix = df_depo[df_depo[\"Fold\"] == \"right-handed beta-helix\"]\n",
    "df_beta_prope = df_depo[df_depo[\"Fold\"] == \"6-bladed beta-propeller\"]\n",
    "\n",
    "def get_labels(df , label = 1) :\n",
    "    labels_df = []\n",
    "    for _,row in df.iterrows():\n",
    "        info = row[\"Boundaries\"]\n",
    "        seq_length = len(row[\"Full_seq\"])\n",
    "        if info == \"full_protein\" :\n",
    "            labels = [label] * seq_length\n",
    "            labels_df.append(labels)\n",
    "        else :\n",
    "            start = int(info.split(\"_\")[-2])\n",
    "            end = int(info.split(\"_\")[-1])\n",
    "            labels = [0 if i < start or i >= end else label for i in range(seq_length)]\n",
    "            labels_df.append(labels)\n",
    "    return labels_df\n",
    "\n",
    "# Beta-helix :\n",
    "labels_beta_helix = get_labels(df_beta_helix , label = 1)\n",
    "seq_beta_helix = df_beta_helix[\"Full_seq\"].to_list()\n",
    "\n",
    "# Beta propeller :\n",
    "labels_beta_propeller = get_labels(df_beta_prope , label = 2)\n",
    "seq_beta_propeller = df_beta_prope[\"Full_seq\"].to_list()\n",
    "\n",
    "# The input data :\n",
    "sequences = seq_beta_helix + seq_beta_propeller\n",
    "labels = labels_beta_helix + labels_beta_propeller\n",
    "\n",
    "\n",
    "# ******************************************************************\n",
    "# DEFINING THE MODEL SIZE : \n",
    "#model_checkpoint = \"facebook/esm2_t6_8M_UR50D\"\n",
    "#model_checkpoint = \"facebook/esm2_t12_35M_UR50D\"\n",
    "model_checkpoint = \"facebook/esm2_t30_150M_UR50D\"\n",
    "\n",
    "\n",
    "# ******************************************************************\n",
    "# PREPROCESS THE DATA FOR THE MODEL :\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "train_tokenized = tokenizer(train_sequences)\n",
    "test_tokenized = tokenizer(test_sequences)\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)\n",
    "\n",
    "num_labels=3\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "from evaluate import load\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "# ******************************************************************\n",
    "# THE SEARCH : \n",
    "\n",
    "logging.basicConfig(filename=f'{path_work}/hyperparameters_tuning.log', level=logging.INFO)\n",
    "\n",
    "class ObjectiveWrapper:\n",
    "    def __init__(self, objective):\n",
    "        self.objective = objective\n",
    "\n",
    "    def __call__(self, trial):\n",
    "        result = self.objective(trial)\n",
    "        # Log the result of each trial\n",
    "        logging.info(f'Trial {trial.number} finished with value: {result} and parameters: {trial.params}.')\n",
    "        return result\n",
    "\n",
    "\n",
    "class MyCallback(TrainerCallback):\n",
    "    def __init__(self, trial: optuna.trial.Trial):\n",
    "        self._trial = trial\n",
    "\n",
    "    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, metrics=None, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            self._trial.report(metrics[\"eval_loss\"], step=state.global_step)\n",
    "            if self._trial.should_prune():\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 8, 16)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-6, 1e-4, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    args = TrainingArguments(\n",
    "        f\"{model_name}-finetuned-depolymerase\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=weight_decay,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        logging_dir='./logs',\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[MyCallback(trial)]\n",
    "    )\n",
    "    trainer.train()\n",
    "    return trainer.evaluate()[\"eval_accuracy\"]\n",
    "\n",
    "\n",
    "\n",
    "#def compute_metrics(eval_pred):\n",
    "#    predictions, labels = eval_pred\n",
    "#    labels = labels.reshape((-1,))\n",
    "#    predictions = np.argmax(predictions, axis=2)\n",
    "#    predictions = predictions.reshape((-1,))\n",
    "#    predictions = predictions[labels!=-100]\n",
    "#    labels = labels[labels!=-100]\n",
    "#    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    labels = labels.reshape((-1,))\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    predictions = predictions.reshape((-1,))\n",
    "    predictions = predictions[labels!=-100]\n",
    "    labels = labels[labels!=-100]\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "\n",
    "wrapper = ObjectiveWrapper(objective)\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner(\n",
    "    n_startup_trials=5,\n",
    "    n_warmup_steps=30\n",
    ")\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n",
    "study.optimize(wrapper, n_trials=10, n_jobs=40)\n",
    "\n",
    "# Log the result of the optimization\n",
    "best_trial = study.best_trial\n",
    "logging.info(f'Best trial finished with value: {best_trial.value} and parameters: {best_trial.params}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#BATCH --job-name=BAYES_search__\n",
    "#SBATCH --qos=long-mem \n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --cpus-per-task=40\n",
    "#SBATCH --mem=300gb \n",
    "#SBATCH --time=2-00:00:00 \n",
    "#SBATCH --output=BAYES_search__%j.log \n",
    "\n",
    "source /storage/apps/ANACONDA/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate embeddings\n",
    "\n",
    "python /home/conchae/PhageDepo_pdb/script_files/bayesian_search.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
